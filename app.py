import streamlit as st
import pandas as pd
from io import BytesIO

st.set_page_config(page_title="ROI æ•¸æ“šè½‰æ›å·¥å…· v3.4", layout="centered")

st.title("ğŸ“Š ROI æ•¸æ“šè‡ªå‹•åˆ†é¡è½‰æ›å™¨")
st.info("ä¿®æ­£ï¼šè§£æ±ºé‡è¤‡ç´¢å¼•å ±éŒ¯ (Reindexing error)ï¼Œä¸¦æ ¡æº– B æ¬„èˆ‡ C æ¬„æ ¼å¼ã€‚")

uploaded_file = st.file_uploader("ä¸Šå‚³åŸå§‹ Excel/CSV", type=["xlsx", "csv"])

if uploaded_file:
    try:
        # --- 1. è®€å–èˆ‡åŸºç¤è™•ç† ---
        file_ext = uploaded_file.name.split('.')[-1].lower()
        df_raw = pd.read_csv(uploaded_file, header=None) if file_ext == 'csv' else pd.read_excel(uploaded_file, header=None)
        
        # å¡«å……è·¨æ¬„æ¨™ç±¤ (Row 2)
        groups = df_raw.iloc[1, :].fillna(method='ffill')
        # å–å¾—æ¨™é¡Œåˆ— (Row 4)
        raw_headers = df_raw.iloc[3, :].astype(str).tolist()
        # æ•¸æ“šä¸»é«” (Row 5+)
        data = df_raw.iloc[4:].copy()

        # è¼”åŠ©å‡½å¼ï¼šç¢ºä¿æ¨™é¡Œæ¸…å–®å”¯ä¸€ (é¿å… Reindexing éŒ¯èª¤)
        def make_unique(cols):
            counts = {}
            new_cols = []
            for col in cols:
                # ç§»é™¤å‰å¾Œç©ºç™½
                c = str(col).strip()
                if c in counts:
                    counts[c] += 1
                    new_cols.append(f"{c}_{counts[c]}")
                else:
                    counts[c] = 0
                    new_cols.append(c)
            return new_cols

        # --- 2. è™•ç† ROI_Business ---
        biz_idx = [0]
        for i in range(1, len(groups)):
            if "KPI" in str(groups[i]).upper():
                biz_idx.append(i)
        
        df_biz = data.iloc[:, biz_idx].copy()
        # è³¦äºˆå”¯ä¸€æ¨™é¡Œ
        biz_header_list = [raw_headers[i] for i in biz_idx]
        biz_header_list[0] = "Date" # å¼·åˆ¶ç¬¬ä¸€æ¬„å« Date
        df_biz.columns = make_unique(biz_header_list)
        df_biz = df_biz.fillna(0)

        # --- 3. è™•ç† ROI_Media (å»ºç«‹ B æ¬„ Media ä¸¦æ¸…ç†æ¨™é¡Œ) ---
        media_idx = [0]
        for i in range(1, len(groups)):
            g_name = str(groups[i]).upper()
            if "MEDIA" in g_name and "NON MEDIA" not in g_name:
                media_idx.append(i)

        # é å…ˆè¨ˆç®—æ¯å€‹æ¬„ä½æ‰€å±¬çš„ Media åˆ†é¡ (åº•ç·šå‰æ–‡å­—)
        col_to_cat = {}
        for i in media_idx:
            if i == 0: 
                col_to_cat[i] = "DATE"
            else:
                h = raw_headers[i]
                col_to_cat[i] = h.split("_")[0].upper() if "_" in h else h.upper()

        # å–å¾—ä¸é‡è¤‡çš„åˆ†é¡æ¸…å–®
        unique_cats = [c for c in list(dict.fromkeys(col_to_cat.values())) if c != "DATE"]
        
        all_media_chunks = []
        for cat in unique_cats:
            # æŒ‘å‡ºå±¬æ–¼è©²åˆ†é¡çš„æ¬„ä½
            cat_sub_idx = [0]
            # æ¸…ç†æ¨™é¡Œï¼šç§»é™¤åª’é«”å‰ç¶´ (ä¾‹å¦‚ç§»é™¤ "META_" æˆ– "meta_")
            cat_sub_headers = ["Date"]
            
            for i in media_idx:
                if i == 0: continue
                if col_to_cat[i] == cat:
                    cat_sub_idx.append(i)
                    # ç§»é™¤å‰ç¶´é‚è¼¯
                    orig_h = raw_headers[i]
                    prefix_lower = f"{cat.lower()}_"
                    prefix_upper = f"{cat.upper()}_"
                    clean_h = orig_h.replace(prefix_lower, "").replace(prefix_upper, "")
                    cat_sub_headers.append(clean_h)
            
            # å»ºç«‹è©²åª’é«”çš„æ•¸æ“šå€å¡Š
            df_temp = data.iloc[:, cat_sub_idx].copy()
            # **é—œéµä¿®æ­£**ï¼šåœ¨è³¦äºˆæ¨™é¡Œå‰å†æ¬¡ç¢ºä¿å”¯ä¸€æ€§ï¼Œé˜²æ­¢ Reindexing éŒ¯èª¤
            df_temp.columns = make_unique(cat_sub_headers)
            
            # åœ¨ B æ¬„æ’å…¥ Media åˆ†é¡
            df_temp.insert(1, 'Media', cat)
            all_media_chunks.append(df_temp)

        # åˆä½µæ‰€æœ‰åª’é«”å€å¡Š
        # ignore_index=True ç¢ºä¿åˆ—ç´¢å¼•é‡æ–°ç·¨è™Ÿï¼Œé¿å…è¡çª
        df_media_final = pd.concat(all_media_chunks, axis=0, ignore_index=True)
        # é€™è£¡ä¸å¼·åˆ¶è£œ 0ï¼Œä»¥ç¬¦åˆæ‰‹ä½œç‰ˆå¯èƒ½å­˜åœ¨çš„ç©ºç™½ç‹€æ…‹ï¼Œæˆ–ä¾éœ€æ±‚è£œ 0
        df_media_final = df_media_final.fillna(0) 

        # --- 4. æ—¥æœŸæ ¼å¼åŒ– ---
        try:
            df_biz.iloc[:, 0] = pd.to_datetime(df_biz.iloc[:, 0]).dt.date
            df_media_final.iloc[:, 0] = pd.to_datetime(df_media_final.iloc[:, 0]).dt.date
        except:
            pass

        # --- 5. ä»‹é¢é¡¯ç¤ºèˆ‡ä¸‹è¼‰ ---
        st.success("âœ… è½‰æ›å®Œæˆï¼å·²ä¿®æ­£é‡è¤‡ç´¢å¼•å•é¡Œã€‚")
        
        st.subheader("ğŸ“ Business æ•¸æ“šé è¦½")
        st.dataframe(df_biz.head(5), use_container_width=True)

        st.subheader("ğŸ“ Media æ•¸æ“šé è¦½ (å·²æ ¡æº– B/C æ¬„)")
        st.dataframe(df_media_final.head(10), use_container_width=True)

        def to_excel(df):
            output = BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                df.to_excel(writer, index=False)
            return output.getvalue()

        st.divider()
        col_dl1, col_dl2 = st.columns(2)
        with col_dl1:
            st.download_button("ğŸ’¾ ä¸‹è¼‰ ROI_Business.xlsx", to_excel(df_biz), "ROI_Business.xlsx", use_container_width=True)
        with col_dl2:
            st.download_button("ğŸ’¾ ä¸‹è¼‰ ROI_Media.xlsx", to_excel(df_media_final), "ROI_Media.xlsx", use_container_width=True)

    except Exception as e:
        st.error(f"âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
