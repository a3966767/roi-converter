import streamlit as st
import pandas as pd
from io import BytesIO

st.set_page_config(page_title="ROI æ•¸æ“šè½‰æ›å·¥å…· v5.1", layout="centered")

st.title("ğŸ“Š ROI æ•¸æ“šè‡ªå‹•åˆ†é¡è½‰æ›å™¨")
st.info("æ ¡æº–ï¼š1.å…¨é¢æ’é™¤ Non-media æ¨™ç±¤ä¸‹çš„æ‰€æœ‰æ¬„ä½ 2.ç²¾ç¢ºæ–‡å­—æ›¿æ› 3.ä¿®æ­£è½‰æ›å ±éŒ¯")

uploaded_file = st.file_uploader("é¸æ“‡åŸå§‹ Excel/CSV", type=["xlsx", "csv"])

if uploaded_file:
    try:
        # 1. è®€å–æ•¸æ“š
        file_ext = uploaded_file.name.split('.')[-1].lower()
        df_raw = pd.read_csv(uploaded_file, header=None) if file_ext == 'csv' else pd.read_excel(uploaded_file, header=None)
        
        # æå–çµæ§‹ (Groups ä½æ–¼ç¬¬äºŒåˆ— Index 1)
        groups = df_raw.iloc[1, :].fillna(method='ffill')
        raw_headers = df_raw.iloc[3, :].astype(str).str.strip().tolist()
        data = df_raw.iloc[4:].copy().reset_index(drop=True)

        # --- 2. è™•ç† Business ---
        biz_idx = [0] + [i for i, g in enumerate(groups) if "KPI" in str(g).upper() and i > 0]
        df_biz = data.iloc[:, biz_idx].copy()
        df_biz.columns = ["Date"] + [raw_headers[i] for i in biz_idx if i > 0]
        df_biz["Date"] = pd.to_datetime(df_biz["Date"], errors='coerce').dt.strftime('%Y-%m-%d')
        for col in df_biz.columns[1:]:
            df_biz[col] = pd.to_numeric(df_biz[col], errors='coerce').fillna(0)

        # --- 3. è™•ç† Media (åš´æ ¼æ’é™¤ Non-media å€é–“) ---
        # é–å®šæ‰€æœ‰æ¨™è¨˜ç‚º Media çš„ç´¢å¼•ï¼Œä½†æ’é™¤æ‰ Group åç¨±åŒ…å« "NON MEDIA" çš„æ‰€æœ‰æ¬„ä½
        media_idx = [0]
        for i, g in enumerate(groups):
            if i == 0: continue
            g_upper = str(g).upper()
            if "MEDIA" in g_upper and "NON MEDIA" not in g_upper:
                media_idx.append(i)
        
        special_keywords = ["OWNED MEDIA", "SHARED MEDIA", "EARNED MEDIA"]
        
        col_mapping = {}
        normal_cats, special_cats = [], []

        for i in media_idx:
            if i == 0: continue
            g_name = str(groups[i]).upper()
            h_name = raw_headers[i]
            parts = h_name.split("_")
            
            is_special = any(k in g_name for k in special_keywords)
            
            if is_special:
                # è¦å‰‡ï¼šå–ç¬¬ä¸€å€‹åº•ç·šå‰ä½œç‚º Media
                cat = parts[0].upper()
                if cat not in special_cats: special_cats.append(cat)
                col_mapping[i] = {"cat": cat, "type": "special"}
            else:
                # è¦å‰‡ï¼šå–æœ€å¾Œä¸€å€‹åº•ç·šå‰ä½œç‚º Media
                cat = "_".join(parts[:-1]).upper() if len(parts) > 1 else h_name.upper()
                if cat not in normal_cats: normal_cats.append(cat)
                col_mapping[i] = {"cat": cat, "type": "normal"}

        # æ’åºï¼šä¸€èˆ¬åœ¨å‰ï¼Œç‰¹æ®Šåœ¨å¾Œ
        final_cat_order = normal_cats + [c for c in special_cats if c not in normal_cats]
        
        # ç²¾ç¢ºæ›¿æ›è¾­å…¸
        rename_dict = {
            "imp": "Impressions",
            "view": "Views",
            "click": "Clicks",
            "spend": "Spend",
            "spent": "Spend",
            "grp": "GRP"
        }

        all_chunks = []
        for cat in final_cat_order:
            target_indices = [i for i, info in col_mapping.items() if info["cat"] == cat]
            if not target_indices: continue
            
            # å»ºç«‹åˆ†é¡æ•¸æ“šå¡Š
            temp_df = pd.DataFrame()
            temp_df["Date"] = pd.to_datetime(data.iloc[:, 0], errors='coerce').dt.strftime('%Y-%m-%d')
            temp_df["Media"] = cat
            temp_df["Product"] = "illuma"
            
            for i in target_indices:
                h_name = raw_headers[i]
                parts = h_name.split("_")
                raw_sub_h = parts[-1].lower()
                
                # ç²¾ç¢ºæ›¿æ›é—œéµå­—
                clean_h = rename_dict.get(raw_sub_h, raw_sub_h.capitalize())
                
                # å¼·åˆ¶å–®æ¬„è½‰å‹ (Series)ï¼Œè§£æ±º Arg å ±éŒ¯
                val_series = pd.to_numeric(data.iloc[:, i], errors='coerce').fillna(0)
                temp_df[clean_h] = val_series
                
            all_chunks.append(temp_df)

        df_media_final = pd.concat(all_chunks, axis=0, ignore_index=True)

        st.success("âœ… è™•ç†å®Œæˆï¼å·²æ’é™¤æ‰€æœ‰ Non-media å€é–“æ¬„ä½ã€‚")

        def to_excel(df):
            output = BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                df.to_excel(writer, index=False)
            return output.getvalue()

        st.divider()
        c1, c2 = st.columns(2)
        with c1: st.download_button("ğŸ’¾ ä¸‹è¼‰ ROI_Business.xlsx", to_excel(df_biz), "ROI_Business.xlsx")
        with c2: st.download_button("ğŸ’¾ ä¸‹è¼‰ ROI_Media.xlsx", to_excel(df_media_final), "ROI_Media.xlsx")

    except Exception as e:
        st.error(f"âŒ è™•ç†å¤±æ•—ï¼š{e}")
